# ðŸ”¥ News


- *2024.09*: ðŸŽ‰ New workshop paper [DAT: Dialogue-Aware Transformer with Modality-Group Fusion for Human Engagement Estimation](https://arxiv.org/abs/2410.08470) is accepted by MM2024.
- *2024.09*: ðŸŽ‰ New paper [UniLearn: Enhancing Dynamic Facial Expression Recognition through Unified Pre-Training and Fine-Tuning on Images and Videos](https://arxiv.org/pdf/2409.06154) is preprinted on arXiv.
- *2024.08*: ðŸŽ‰ One paper [From Static to Dynamic: Adapting Landmark-Aware Image Models for Facial Expression Recognition in Videos](https://arxiv.org/abs/2312.05447) is accepted by TAFFC.

<!-- - *2023.12*: ðŸŽ‰ ~~New paper [From Static to Dynamic: Adapting Landmark-Aware Image Models for Facial Expression Recognition in Videos](https://arxiv.org/abs/2312.05447) is preprinted on arXiv.~~
- *2023.05*: ðŸŽ‰ One paper [Multimodal feature extraction and fusion for emotional reaction intensity estimation and expression classification in videos with transformers](https://openaccess.thecvf.com/content/CVPR2023W/ABAW/html/Li_Multimodal_Feature_Extraction_and_Fusion_for_Emotional_Reaction_Intensity_Estimation_CVPRW_2023_paper.html) is accepted by CVPRW 2023
- *2023.04*: ðŸŽ‰ **First place** of Emotional Reaction Intensity (ERI) Estimation Challenge in [CVPR2023-ABAW5](https://ibug.doc.ic.ac.uk/resources/cvpr-2023-5th-abaw/)
- *2023.04*: ðŸ”¥ We release [CVPR2023-ABAW5-ERI](https://github.com/cyinen/CVPR2023-ABAW5-ERI) -->
